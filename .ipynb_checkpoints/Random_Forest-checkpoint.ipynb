{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h2> Random Forest </h2> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"pics/RF.png\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> <font color=\"blue\"> Pros </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Decision Trees gets to \"overfitting\" if not pruned properly. Random Forest eliminates it.The votes (classification) and estimates (regression) are \"counted\" or \"averaged\" across many trees. Decorrelation happens since the \"features\" are selected at \"random\" from the subset of feature space.\n",
    "2. Since this is \"wisdom of crowd\" or \"ensemble\" method, it is less likely to prone to small changes in the datasets.\n",
    "3. Works well with **high-dimesnion** data.\n",
    "4. Paralleization : Splitting the process across many machine is easy and hence the computation speed can be made fast.\n",
    "4. Similar to Decision Tree , Random Forests can handle outliers and non linear data very well.\n",
    "5. Unbalanced data can be handled well, though this is easily possible in all other \"tree\" like approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> <font color = \"red\"> Cons </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Since we are building many trees and hence the process may take time and can be expensive in terms of memory consumption.\n",
    "2. Random Forest can still **overfit** so be careful with the **hyper-parameter**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> <font color = \"green\"> How it works </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> It is a simple model if you understand how Decision Trees work. The Random Forest is a collection of many trees,\n",
    "    where features AND data points are selected randomly to create \"de-correlated\" trees. </p>\n",
    "<p> Bootstrapping (random sampling with replacement) is done for each data point. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> <span style=\"background:yellow\"> Hyper-parameters </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Maximum Depth** : Careful with overfitting.\n",
    "2. **Number of Trees** : Generally higher the number the better. Computationally expensise though.\n",
    "3. **Max Features** : Size of random feature when looking for best split at each node. \n",
    "4. **Split Criterion** : Gini or Entropy. Normally either gives good result. Problem specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = pd.read_csv('/Users/bt/Documents/GITHUB/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit.drop('Time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = credit.drop('Class', axis=1)\n",
    "y = credit[['Class']]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y,stratify=y,test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "\n",
    "X_valid = sc.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100,max_features='sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='sqrt')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Pred:Yes  Pred:No\n",
      "Actual:Yes     85288        7\n",
      "Actual:No         30      118\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(confusion_matrix(y_valid,predictions), columns=['Pred:Yes','Pred:No'], index=['Actual:Yes','Actual:No']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.9995669627705019\n",
      "Recall Score : 0.7972972972972973\n",
      "Precision Score : 0.944\n",
      "F1 Score : 0.8644688644688644\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score : ' + str(accuracy_score(y_valid,predictions)))\n",
    "print('Recall Score : ' + str(recall_score(y_valid,predictions)))\n",
    "print('Precision Score : ' + str(precision_score(y_valid,predictions)))\n",
    "print('F1 Score : ' + str((f1_score(y_valid,predictions)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predcited = cross_validate(model,X_train,y_train.values.ravel(),cv=5,scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.790537084398977\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(predcited['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': None,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start=400,stop=600,num=2)]\n",
    "max_depth = [int(x) for x in np.linspace(10,20,num=2)]\n",
    "min_samples_split = [10,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {'n_estimators' : n_estimators,\n",
    "              'max_depth' : max_depth,\n",
    "              'min_samples_split' : min_samples_split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [10, 20],\n",
      " 'min_samples_split': [10, 20],\n",
      " 'n_estimators': [400, 600]}\n"
     ]
    }
   ],
   "source": [
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_grid = RandomizedSearchCV(rf, param_distributions=random_grid, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bt/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:278: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [10, 20],\n",
       "                                        'min_samples_split': [10, 20],\n",
       "                                        'n_estimators': [400, 600]})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random_grid.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 600, 'min_samples_split': 10, 'max_depth': 20}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994984051792208"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = RandomForestClassifier(**rf_random_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=20, min_samples_split=10, n_estimators=600)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is : 0.9995435553526912\n",
      "The recall score is : 0.7905405405405406\n",
      "The precision score is :0.936\n",
      "The F1 Score is : 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# Let's find out the various metrics\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "\n",
    "print(\"The accuracy score is : \" + str(accuracy_score(y_valid,predictions)))\n",
    "print(\"The recall score is : \" + str(recall_score(y_valid,predictions)))\n",
    "print(\"The precision score is :\" + str(precision_score(y_valid,predictions)))\n",
    "print(\"The F1 Score is : \" + str(f1_score(y_valid,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.94      0.79      0.86       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.97      0.90      0.93     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's see the classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_valid,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Predicted: 0  Predicted : 1\n",
      "Actual : 0         85287              8\n",
      "Actual : 1            31            117\n"
     ]
    }
   ],
   "source": [
    "# Let's see the confusion matrix to make things clear\n",
    "\n",
    "print(pd.DataFrame(confusion_matrix(y_valid,predictions),columns=['Predicted: 0','Predicted : 1'],\\\n",
    "                   index=['Actual : 0', 'Actual : 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_valid,predictions).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85287  : Were actually 0 and were predicted 0\n",
      "117 : Were actually 1 and were predicted 1\n",
      "8 : Were actually 0 but were predicted 1\n",
      "31 : Were actually 1 but were predicted 0\n"
     ]
    }
   ],
   "source": [
    "print(tn ,\" : Were actually 0 and were predicted 0\")\n",
    "print(tp , \": Were actually 1 and were predicted 1\")\n",
    "print(fp, \": Were actually 0 but were predicted 1\")\n",
    "print(fn, \": Were actually 1 but were predicted 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
